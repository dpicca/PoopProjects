{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Faire un for chaque dossier dans dossier movies (chaque genre), for chaque file dans le dossier de ce genre, readlines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"./data/dialogs_movies\"\n",
    "\n",
    "for folder in os.listdir(path):\n",
    "    #print(folder)\n",
    "    for file in os.listdir(path+\"/\"+folder):\n",
    "        #print(file)\n",
    "        with open(\"../2021_22/data/dialogs_movies/\" + folder + \"/\" + file, \"r\") as f :\n",
    "            document = f.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', None), ('went', Synset('run_low.v.01')), ('to', None), ('the', None), ('bank', Synset('bank.n.09')), ('to', None), ('deposit', Synset('deposit.v.02')), ('my', None), ('money', Synset('money.n.03'))]\n"
     ]
    },
    {
     "data": {
      "text/plain": "      Word                  Synset\n0        I                    None\n1     went  Synset('run_low.v.01')\n2       to                    None\n3      the                    None\n4     bank     Synset('bank.n.09')\n5       to                    None\n6  deposit  Synset('deposit.v.02')\n7       my                    None\n8    money    Synset('money.n.03')",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Synset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>went</td>\n      <td>Synset('run_low.v.01')</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>to</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>the</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bank</td>\n      <td>Synset('bank.n.09')</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>to</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>deposit</td>\n      <td>Synset('deposit.v.02')</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>my</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>money</td>\n      <td>Synset('money.n.03')</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pywsd import disambiguate\n",
    "import pandas as pd\n",
    "\n",
    "print(disambiguate('I went to the bank to deposit my money'))\n",
    "\n",
    "disambiguate_dialog_df = pd.DataFrame(disambiguate('I went to the bank to deposit my money'),\n",
    "                                      columns = [\"Word\", \"Synset\"])\n",
    "\n",
    "disambiguate_dialog_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0          I\n1       went\n2         to\n3        the\n4       bank\n5         to\n6    deposit\n7         my\n8      money\nName: Word, dtype: object"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disambiguate_dialog_df[\"Word\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "[0,\n 0.253,\n 0.091,\n 0,\n '#serenity',\n '#acceptance',\n 'positive',\n 0.172,\n 'sticker',\n 'dollar_sign',\n 'monetary',\n 'value',\n 'money_value']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import senticnet\n",
    "\n",
    "senticnet.senticnet['money']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.553, 0, -0.349, 0, '#sadness', '#disgust', 'negative', -0.451, 'uncalled_for', 'unwant', 'unfriendless', 'cast_off', 'unwelcome']\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "not found\n",
      "[-0.917, 0, -0.795, 0, '#grief', '#loathing', 'negative', -0.856, 'impudent', 'alluvial', 'brash', 'rock', 'insensitive']\n",
      "not found\n",
      "[0, 0.253, 0.091, 0, '#serenity', '#acceptance', 'positive', 0.172, 'sticker', 'dollar_sign', 'monetary', 'value', 'money_value']\n"
     ]
    }
   ],
   "source": [
    "#disambiguiate string\n",
    "from pywsd import disambiguate\n",
    "import pandas as pd\n",
    "#search in senticnet\n",
    "import senticnet\n",
    "\n",
    "disambiguate_dialog_df = pd.DataFrame(disambiguate('abandon I went to the bank to deposit my money'),\n",
    "                                      columns = [\"Word\", \"Synset\"])\n",
    "\n",
    "\n",
    "for word in disambiguate_dialog_df[\"Word\"]:\n",
    "    if word in senticnet.senticnet:\n",
    "        print(senticnet.senticnet[word])\n",
    "    else:\n",
    "        print(\"not found\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Word                    Synset 1st Emotion  2nd Emotion\n",
      "0     abandon   Synset('wildness.n.01')    #sadness     #disgust\n",
      "1           I                      None   not found    not found\n",
      "2        went    Synset('run_low.v.01')   not found    not found\n",
      "3          to                      None   not found    not found\n",
      "4         the                      None   not found    not found\n",
      "5        bank       Synset('bank.n.09')   not found    not found\n",
      "6          to                      None   not found    not found\n",
      "7     deposit    Synset('deposit.v.02')      #grief    #loathing\n",
      "8          my                      None   not found    not found\n",
      "9       money      Synset('money.n.03')   #serenity  #acceptance\n",
      "10  abashment  Synset('abashment.n.01')    #dislike         None\n"
     ]
    }
   ],
   "source": [
    "#disambiguiate string\n",
    "from pywsd import disambiguate\n",
    "import pandas as pd\n",
    "#search in senticnet\n",
    "import senticnet\n",
    "\n",
    "disambiguate_dialog_df = pd.DataFrame(disambiguate('abandon I went to the bank to deposit my money abashment'),\n",
    "                                      columns = [\"Word\", \"Synset\"])\n",
    "\n",
    "list_1st_emotion = []\n",
    "list_2nd_emotion = []\n",
    "for word in disambiguate_dialog_df[\"Word\"]:\n",
    "    word_low = word.lower()\n",
    "    if word_low in senticnet.senticnet.keys():\n",
    "        list_1st_emotion.append(senticnet.senticnet[word_low][4])\n",
    "        list_2nd_emotion.append(senticnet.senticnet[word_low][5])\n",
    "    else:\n",
    "        list_1st_emotion.append(\"not found\")\n",
    "        list_2nd_emotion.append(\"not found\")\n",
    "\n",
    "disambiguate_dialog_df[\"1st Emotion\"] = list_1st_emotion\n",
    "disambiguate_dialog_df[\"2nd Emotion\"] = list_2nd_emotion\n",
    "\n",
    "print(disambiguate_dialog_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '01\\'\">'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [25]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m synset \u001B[38;5;129;01min\u001B[39;00m disambiguate_dialog_df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSynset\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m     23\u001B[0m         match_group_synset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(re\u001B[38;5;241m.\u001B[39msearch(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(?<=Synset\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m()[^)]+\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mstr\u001B[39m(synset)))\n\u001B[0;32m---> 24\u001B[0m         synonym \u001B[38;5;241m=\u001B[39m \u001B[43mwn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msynset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmatch_group_synset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m         disambiguate_dialog_df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSynonyme\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m synonym\u001B[38;5;241m.\u001B[39mhypernyms()\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/PoopProjects_1/venv/lib/python3.8/site-packages/nltk/corpus/reader/wordnet.py:1435\u001B[0m, in \u001B[0;36mWordNetCorpusReader.synset\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1432\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msynset\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n\u001B[1;32m   1433\u001B[0m     \u001B[38;5;66;03m# split name into lemma, part of speech and synset number\u001B[39;00m\n\u001B[1;32m   1434\u001B[0m     lemma, pos, synset_index_str \u001B[38;5;241m=\u001B[39m name\u001B[38;5;241m.\u001B[39mlower()\u001B[38;5;241m.\u001B[39mrsplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m-> 1435\u001B[0m     synset_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msynset_index_str\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1437\u001B[0m     \u001B[38;5;66;03m# get the offset for this synset\u001B[39;00m\n\u001B[1;32m   1438\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: invalid literal for int() with base 10: '01\\'\">'"
     ]
    }
   ],
   "source": [
    "#disambiguiate string\n",
    "from pywsd import disambiguate\n",
    "import pandas as pd\n",
    "#search in senticnet\n",
    "import senticnet\n",
    "from nltk.corpus import wordnet as wn\n",
    "import re\n",
    "\n",
    "disambiguate_dialog_df = pd.DataFrame(disambiguate('abandon I went to the bank to deposit my money abashment the Russian Republican Army, secured we legitimize terror Gentlemen, welcome to Air Force One.'),\n",
    "                                      columns = [\"Word\", \"Synset\"])\n",
    "\n",
    "list_1st_emotion = []\n",
    "list_2nd_emotion = []\n",
    "for word in disambiguate_dialog_df[\"Word\"]:\n",
    "    if word in senticnet.senticnet.keys():\n",
    "        list_1st_emotion.append(senticnet.senticnet[word][4])\n",
    "        list_2nd_emotion.append(senticnet.senticnet[word][5])\n",
    "    elif word in senticnet.senticnet.values():\n",
    "        list_1st_emotion.append(senticnet.senticnet[word][4])\n",
    "        list_2nd_emotion.append(senticnet.senticnet[word][5])\n",
    "    elif word not in senticnet.senticnet.keys() and senticnet.senticnet.values():\n",
    "        for synset in disambiguate_dialog_df[\"Synset\"]:\n",
    "            match_group_synset = str(re.search(\"(?<=Synset\\()[^)]+\", str(synset)))\n",
    "            synonym = wn.synset(match_group_synset)\n",
    "            disambiguate_dialog_df[\"Synonyme\"] = synonym.hypernyms()\n",
    "    else:\n",
    "        list_1st_emotion.append(\"not found\")\n",
    "        list_2nd_emotion.append(\"not found\")\n",
    "\n",
    "disambiguate_dialog_df[\"1st Emotion\"] = list_1st_emotion\n",
    "disambiguate_dialog_df[\"2nd Emotion\"] = list_2nd_emotion\n",
    "\n",
    "print(disambiguate_dialog_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('run_low.v.01')\n",
      "[Synset('end.v.01')]\n"
     ]
    }
   ],
   "source": [
    "synonym = wn.synset(\"run_low.v.01\")\n",
    "print(synonym)\n",
    "print(synonym.hypernyms())\n",
    "#disambiguate_dialog_df[\"Synonyme\"] = synonym.synonyms()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'abashment.n.01'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "match_group = re.search(\"(?<=Synset\\()[^)]+\", \"Synset('abashment.n.01')\")\n",
    "\n",
    "print(match_group.group())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'dog.n.01'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "dog = wn.synsets('dog')[0].name()\n",
    "\n",
    "dog\n",
    "\n",
    "#dog.name()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}