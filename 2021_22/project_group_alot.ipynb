{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#import random\n",
    "\n",
    "#with open(\"../2021_22/data/dialogs_movies/Action/15minutes_dialog.txt\", \"r\") as file:\n",
    " #   my_dialog = file.read()\n",
    "  #  words = list(map(str, my_dialog.split()))\n",
    "\n",
    "   # print(random.choice(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#for each_genre in dialogs_movies:\n",
    "    #for each_file in dialogs :\n",
    "        #readlines regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#import csv\n",
    "\n",
    "path = \"./data/dialogs_movies\"\n",
    "\n",
    "for folder in os.listdir(path):\n",
    "    # print(folder)\n",
    "    for file in os.listdir(path+\"/\"+folder):\n",
    "        with open(\"../2021_22/data/dialogs_movies/\"+folder+\"/\"+file, \"r\") as f :\n",
    "            document = f.read()\n",
    "\n",
    "            # Fermer après read() et stocker dans variable\n",
    "            # Stocker après dans CSV 1 script/tableau\n",
    "            #if \"speaker.found\" :\n",
    "             #   my_speeches[speaker]=\"\"\n",
    "            #elif \"speech.found\" :\n",
    "             #   my_speech [speaker]=[speech.found]\n",
    "            #else :\n",
    "                # \"not in RG\"\n",
    "             #   pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', None), ('went', Synset('run_low.v.01')), ('to', None), ('the', None), ('bank', Synset('bank.n.09')), ('to', None), ('deposit', Synset('deposit.v.02')), ('my', None), ('money', Synset('money.n.03'))]\n"
     ]
    }
   ],
   "source": [
    "from pywsd import disambiguate\n",
    "\n",
    "print(disambiguate('I went to the bank to deposit my money'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', None), ('went', Synset('run_low.v.01')), ('to', None), ('the', None), ('bank', Synset('bank.n.09')), ('to', None), ('deposit', Synset('deposit.v.02')), ('my', None), ('money', Synset('money.n.03'))]\n",
      "       Word                  Synset\n",
      "0         i                    None\n",
      "1      went  Synset('run_low.v.01')\n",
      "2        to                    None\n",
      "3       the                    None\n",
      "4      bank     Synset('bank.n.09')\n",
      "5        to                    None\n",
      "6   deposit  Synset('deposit.v.02')\n",
      "7        my                    None\n",
      "8     money    Synset('money.n.03')\n",
      "9   because                    None\n",
      "10     they                    None\n",
      "11  abandon   Synset('vacate.v.02')\n",
      "12     your                    None\n",
      "13    money    Synset('money.n.03')\n",
      "14    hello    Synset('hello.n.01')\n"
     ]
    }
   ],
   "source": [
    "from pywsd import disambiguate\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet as wn\n",
    "import re\n",
    "\n",
    "print(disambiguate('I went to the bank to deposit my money'))\n",
    "\n",
    "disambiguate_dialog_df = pd.DataFrame(disambiguate('i went to the bank to deposit my money because they abandon your money hello'),\n",
    "                                      columns = [\"Word\", \"Synset\"])\n",
    "\n",
    "print(disambiguate_dialog_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.553, 0, -0.349, 0, '#sadness', '#disgust', 'negative', -0.451, 'uncalled_for', 'unwant', 'unfriendless', 'cast_off', 'unwelcome']\n",
      "sorry\n",
      "sorry\n",
      "sorry\n",
      "sorry\n",
      "sorry\n",
      "sorry\n",
      "[-0.917, 0, -0.795, 0, '#grief', '#loathing', 'negative', -0.856, 'impudent', 'alluvial', 'brash', 'rock', 'insensitive']\n",
      "sorry\n",
      "[0, 0.253, 0.091, 0, '#serenity', '#acceptance', 'positive', 0.172, 'sticker', 'dollar_sign', 'monetary', 'value', 'money_value']\n"
     ]
    }
   ],
   "source": [
    "import senticnet\n",
    "phrase = \"abandon i went to the bank to deposit my money\"\n",
    "words = phrase.split(\" \")\n",
    "for word in words :\n",
    "    if word in senticnet.senticnet:\n",
    "        print(senticnet.senticnet[word])\n",
    "    else :\n",
    "        print(\"sorry\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Word                  Synset  1st Emotion  2nd Emotion\n",
      "0         i                    None       #grief    #loathing\n",
      "1      went  Synset('run_low.v.01')    not found    not found\n",
      "2        to                    None    not found    not found\n",
      "3       the                    None    not found    not found\n",
      "4      bank     Synset('bank.n.09')       #grief    #loathing\n",
      "5        to                    None    not found    not found\n",
      "6   deposit  Synset('deposit.v.02')       #grief    #loathing\n",
      "7        my                    None    not found    not found\n",
      "8     money    Synset('money.n.03')    #serenity  #acceptance\n",
      "9   because                    None    not found    not found\n",
      "10     they                    None    not found    not found\n",
      "11  abandon   Synset('vacate.v.02')     #sadness     #disgust\n",
      "12     your                    None    not found    not found\n",
      "13    money    Synset('money.n.03')    #serenity  #acceptance\n",
      "14    hello    Synset('hello.n.01')  #enthusiasm         None\n"
     ]
    }
   ],
   "source": [
    "list_1st_emotion = []\n",
    "list_2nd_emotion = []\n",
    "\n",
    "for w in disambiguate_dialog_df[\"Word\"]:\n",
    "    #wm=w.lower()\n",
    "\n",
    "    if w in senticnet.senticnet.keys():\n",
    "        #mylist = senticnet.senticnet[wm]\n",
    "        #print(f'key for word {wm} : {senticnet.senticnet[wm]} which sentiments are : {senticnet.senticnet[wm][4]} and {mylist[5].strip(\"#\")}')\n",
    "        list_1st_emotion.append(senticnet.senticnet[w][4])\n",
    "        list_2nd_emotion.append(senticnet.senticnet[w][5])\n",
    "    elif w in senticnet.senticnet.values():\n",
    "        list_1st_emotion.append(senticnet.senticnet[w][4])\n",
    "        list_2nd_emotion.append(senticnet.senticnet[w][5])\n",
    "        print(\"Synonyme\")\n",
    "    elif w not in senticnet.senticnet.keys() and senticnet.senticnet.values() :\n",
    "        check_w = wn.synsets(w)\n",
    "        if check_w:\n",
    "            word = wn.synsets(w)[0]\n",
    "            check_hypernym = word.hypernyms()\n",
    "            if check_hypernym :\n",
    "                hypernym_word = word.hypernyms()[0]\n",
    "                regex = re.compile(\"(?<=Synset\\(')[^_.]+\")\n",
    "                regex_word = str(regex.findall(str(hypernym_word)))\n",
    "                ok_word_1 = regex_word.replace(\"['\", \"\")\n",
    "                ok_word_2 = ok_word_1.replace(\"']\", \"\")\n",
    "                if ok_word_2 in senticnet.senticnet.keys() or senticnet.senticnet.values() :\n",
    "                    emotion_1 = senticnet.senticnet[ok_word_2][4]\n",
    "                    emotion_2 = senticnet.senticnet[ok_word_2][5]\n",
    "                    list_1st_emotion.append(emotion_1)\n",
    "                    list_2nd_emotion.append(emotion_2)\n",
    "            else :\n",
    "                list_1st_emotion.append(\"not found\")\n",
    "                list_2nd_emotion.append(\"not found\")\n",
    "        else:\n",
    "            list_1st_emotion.append(\"not found\")\n",
    "            list_2nd_emotion.append(\"not found\")\n",
    "\n",
    "disambiguate_dialog_df[\"1st Emotion\"] = list_1st_emotion\n",
    "disambiguate_dialog_df[\"2nd Emotion\"] = list_2nd_emotion\n",
    "\n",
    "print(disambiguate_dialog_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "dog.hypernyms()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('canine.n.02')\n",
      "['canine']\n",
      "canine\n",
      "#responsiveness\n"
     ]
    }
   ],
   "source": [
    "dog = wn.synsets('dog')[0]\n",
    "hypernym_dog = dog.hypernyms()[0]\n",
    "print(hypernym_dog)\n",
    "regex = re.compile(\"(?<=Synset\\(')[^.]+\")\n",
    "regex_dog = str()\n",
    "regex_dog = str(regex.findall(str(hypernym_dog)))\n",
    "print(regex_dog)\n",
    "ok_dog_1 = regex_dog.replace(\"['\", \"\")\n",
    "ok_dog_2 = ok_dog_1.replace(\"']\", \"\")\n",
    "print(ok_dog_2)\n",
    "print(senticnet.senticnet[ok_dog_2][4])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "if ok_dog_2 in senticnet.senticnet.keys() :\n",
    "    print(\"hello\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "to = wn.synsets(\"to\")\n",
    "print(to)\n",
    "if to :\n",
    "    print(\"hello\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "went = wn.synsets(\"went\")[0]\n",
    "hypernym_went = went.hypernyms()\n",
    "print(hypernym_went)\n",
    "if hypernym_went:\n",
    "    print(\"ça marche\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  speaker                                          speech  \\\n",
      "0   Rohan  abandon i went to the bank to deposit my money   \n",
      "1  Elvish  abandon i went to the bank to deposit my money   \n",
      "2  Deepak  abandon i went to the bank to deposit my money   \n",
      "\n",
      "                                       disambiguated  \n",
      "0  [(abandon, Synset('wildness.n.01')), (i, None)...  \n",
      "1  [(abandon, Synset('wildness.n.01')), (i, None)...  \n",
      "2  [(abandon, Synset('wildness.n.01')), (i, None)...  \n",
      "this is my word abandon and this is my synset Synset('wildness.n.01')\n",
      "this is my word i and this is my synset None\n",
      "this is my word went and this is my synset Synset('run_low.v.01')\n",
      "this is my word to and this is my synset None\n",
      "this is my word the and this is my synset None\n",
      "this is my word bank and this is my synset Synset('bank.n.09')\n",
      "this is my word to and this is my synset None\n",
      "this is my word deposit and this is my synset Synset('deposit.v.02')\n",
      "this is my word my and this is my synset None\n",
      "this is my word money and this is my synset Synset('money.n.03')\n",
      "this is my word abandon and this is my synset Synset('wildness.n.01')\n",
      "this is my word i and this is my synset None\n",
      "this is my word went and this is my synset Synset('run_low.v.01')\n",
      "this is my word to and this is my synset None\n",
      "this is my word the and this is my synset None\n",
      "this is my word bank and this is my synset Synset('bank.n.09')\n",
      "this is my word to and this is my synset None\n",
      "this is my word deposit and this is my synset Synset('deposit.v.02')\n",
      "this is my word my and this is my synset None\n",
      "this is my word money and this is my synset Synset('money.n.03')\n",
      "this is my word abandon and this is my synset Synset('wildness.n.01')\n",
      "this is my word i and this is my synset None\n",
      "this is my word went and this is my synset Synset('run_low.v.01')\n",
      "this is my word to and this is my synset None\n",
      "this is my word the and this is my synset None\n",
      "this is my word bank and this is my synset Synset('bank.n.09')\n",
      "this is my word to and this is my synset None\n",
      "this is my word deposit and this is my synset Synset('deposit.v.02')\n",
      "this is my word my and this is my synset None\n",
      "this is my word money and this is my synset Synset('money.n.03')\n"
     ]
    }
   ],
   "source": [
    "from pywsd import disambiguate\n",
    "import pandas as pd\n",
    "values= [['Rohan','abandon i went to the bank to deposit my money'],['Elvish','abandon i went to the bank to deposit my money'],['Deepak','abandon i went to the bank to deposit my money'],\n",
    "        ]\n",
    "\n",
    "disambigauted_df = pd.DataFrame(values,columns=['speaker','speech'])\n",
    "\n",
    "disambigauted_df=disambigauted_df.astype('string')\n",
    "disambigauted_df['disambiguated']=disambigauted_df.speech.apply(lambda x: disambiguate(x))\n",
    "\n",
    "print(disambigauted_df)\n",
    "\n",
    "for each in disambigauted_df.disambiguated:\n",
    "    for word,synset in each:\n",
    "        print(f'this is my word {word} and this is my synset {synset}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "speaker = [A-Z]{2}.+\n",
    "\n",
    "speech = ^(?![A-Z]{2}).*$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}